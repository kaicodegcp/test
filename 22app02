 Final Fix Steps
🔹 1. Identify the Actual SA Used by the Failing Pod
Run this again and capture the actual service account:

bash
Copy
Edit
oc get pod -n cdp2 -o jsonpath='{range .items[*]}{@.metadata.name}: {@.spec.serviceAccountName}{"\n"}{end}'
Look for the pod involved in the Vault install (e.g., vault-0, cdp-preinstall, etc.)

🔹 2. Assign Required Role to That Service Account
Now use that real SA (say default or vault-auth) and run:

bash
Copy
Edit
oc adm policy add-role-to-user view system:serviceaccount:cdp2:vault-auth -n cdp2
Or if Vault is using default SA:

bash
Copy
Edit
oc adm policy add-role-to-user view system:serviceaccount:cdp2:default -n cdp2
🔹 3. [Optional] If view is not enough, assign edit or custom drs ClusterRole
bash
Copy
Edit
oc adm policy add-cluster-role-to-user drs system:serviceaccount:cdp2:vault-auth
Replace drs with the name shown in cloudera-cdp2-drs or k8s-cdp2-drs depending on which fits your Vault flow policy.

🔹 4. Restart Pod or Retry the Vault Workflow
bash
Copy
Edit
oc delete pod <vault-pod-name> -n cdp2



=============
Step-by-Step Manual Vault Login Test (Kubernetes Auth)
🔹 1. Extract the JWT Token from a Pod
bash
Copy
Edit
oc get pod -n cdp2
Pick a running pod using the correct service account (e.g., vault-auth or default).

Then:

bash
Copy
Edit
oc exec -n cdp2 <pod-name> -- cat /var/run/secrets/kubernetes.io/serviceaccount/token > jwt-token.txt
🔹 2. Create the Login Payload
Create a file called vault-login.json:

json
Copy
Edit
{
  "jwt": "<paste contents of jwt-token.txt here>",
  "role": "cdp2-role"
}
Replace "cdp2-role" with the name of the Vault Kubernetes role that was configured for this workflow.

🔹 3. Send the API Request Using curl
bash
Copy
Edit
curl -v -k \
  --cert /etc/docker/certs.d/sd-wv58-kflz.nam.nsroot.net:5000/domain.crt \
  --key /etc/docker/certs.d/sd-wv58-kflz.nam.nsroot.net:5000/domain.key \
  -X POST https://vault-cdp2-vault.apps.mlab-ctgitdcai03d.ecs.dyn.nsroot.net/v1/auth/cdp2/login \
  -H "Content-Type: application/json" \
  -d @vault-login.json


=============================================
How to Fix It
🔧 Option 1: Patch Live ResourceQuota
Use oc patch to avoid resourceVersion conflicts:

bash
Copy
Edit
oc patch resourcequota compute-resources -n cdp2 --type=merge -p '{
  "spec": {
    "hard": {
      "limits.cpu": "100",
      "limits.memory": "500Gi",
      "pods": "90",
      "requests.cpu": "90",
      "requests.memory": "500Gi"
    }
  }
}'
This directly updates the live quota without replacing the full object.

🔁 Option 2: Refresh and Reapply the Latest YAML
If you prefer editing YAML:

Export the live object without resourceVersion and status:

bash
Copy
Edit
oc get resourcequota compute-resources -n cdp2 -o yaml > updated-rq.yaml
Edit updated-rq.yaml:

Remove the entire status: block.

Remove the creationTimestamp, resourceVersion, and uid fields under metadata:.

Keep only:

yaml
Copy
Edit
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources
  namespace: cdp2
spec:
  hard:
    limits.cpu: "100"
    limits.memory: 500Gi
    pods: "90"
    requests.cpu: "90"
    requests.memory: 500Gi
Apply the cleaned-up version:

bash
Copy
Edit
oc apply -f updated-rq.yaml
🧼 Optional: Delete and Recreate the Quota (Only if Safe)
If no production workloads are depending on the quota:

bash
Copy
Edit
oc delete resourcequota compute-resources -n cdp2
oc apply -f rq-compute-cdp2.yaml

